{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMr9grNwdN8N"
   },
   "outputs": [],
   "source": [
    "# !pip install python-dotenv>=0.5.1\n",
    "# !pip install scikit-learn==1.2.2\n",
    "# !pip install matplotlib==3.7.3\n",
    "# !pip install wordcloud==1.9.2\n",
    "# !pip install tensorflow==2.10.1\n",
    "# !pip install opt_einsum==3.3.0\n",
    "# !pip install gast==0.5.4\n",
    "# !pip install astunparse==1.6.3\n",
    "# !pip install h5py==3.9.0\n",
    "# !pip install future==0.18.3\n",
    "# !pip install openpyxl==3.1.2\n",
    "# !pip install torch==2.0.1\n",
    "# !pip install torchvision==0.15.2\n",
    "# !pip install torchaudio==2.0.2\n",
    "# !pip install pandas==1.1.0\n",
    "# !pip install sage-importance\n",
    "# !pip install shap==0.42.1\n",
    "# !pip install shap==0.42.1\n",
    "# !pip install Imbalanced-learn==0.11.0\n",
    "# !pip install xgboost==2.0.0\n",
    "# !pip install numpy==1.23.5\n",
    "# !pip install torchmetrics==1.2.0\n",
    "# !pip install lifelines==0.27.8\n",
    "# !pip install joblib==1.3.2\n",
    "# !pip install boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YnMk0sKkjlj8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "directory_path = input(\"Enter your file directory: \")\n",
    "os.chdir(directory_path)\n",
    "\n",
    "from feature_selection_timeseries.src.models.pipeline import run\n",
    "from feature_selection_timeseries.src.models.utils import create_time_feature, tune_cv_split, convert_to_sample \n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OuCvzIsjlkA"
   },
   "source": [
    "### Create Sample Data (Filter for data with the date specified)\n",
    "\n",
    "##### The 11 stocks file can be downloaded via the URL link below (request for access required):\n",
    "\n",
    "##### https://drive.google.com/drive/folders/1yN-JTu9pvL8Tm2xTSiK5L8F_L1tIWxoQ?usp=sharing\n",
    "\n",
    "##### After completing the downloads, add the files to the directory: ./feature_selection_timeseries/data/raw/sp500_subset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YpsF6U-bjlkB"
   },
   "outputs": [],
   "source": [
    "year = \"2006\"\n",
    "date_threshold = year + '-01-01'  # filter for data with date >=\n",
    "sub_folder = \"sp500_subset\"\n",
    "\n",
    "# path of the file containing the features\n",
    "x_filename_in = 'stock_x.csv'\n",
    "x_filename_out = f'stock_x_sample_regression_{year}_filtered_11_stocks.csv'\n",
    "x_in_path = f'./feature_selection_timeseries/data/raw/{sub_folder}/'\n",
    "x_out_path = f'./feature_selection_timeseries/data/raw/{sub_folder}/'\n",
    "\n",
    "# path of the file containing the label\n",
    "y_filename_in = 'stock_y_ret84.csv'\n",
    "y_filename_out = f'stock_y_ret84_sample_regression_{year}_filtered_11_stocks.csv'\n",
    "y_in_path = x_in_path\n",
    "y_out_path = x_out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYbCnSs8eKq-"
   },
   "source": [
    "### Filter Data and Generate New Files\n",
    "\n",
    "#### Run the codes below if you want to filter the original dataset for a selected subset of stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9cTVKe9q7Toq"
   },
   "outputs": [],
   "source": [
    "# stocks=[\n",
    "#     \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\", \"NVDA\", \"TSLA\"\n",
    "# ]\n",
    "\n",
    "# convert_to_sample(\n",
    "#     path_in=x_in_path,\n",
    "#     path_out=x_out_path,\n",
    "#     filename_in = x_filename_in,\n",
    "#     filename_out = x_filename_out,\n",
    "#     date_threshold=date_threshold,\n",
    "#     filter_type=\"combined stocks\",\n",
    "#     stocks=stocks\n",
    "# )\n",
    "\n",
    "# convert_to_sample(\n",
    "#     path_in=y_in_path,\n",
    "#     path_out=y_out_path,\n",
    "#     filename_in = y_filename_in,\n",
    "#     filename_out = y_filename_out,\n",
    "#     date_threshold=date_threshold,\n",
    "#     filter_type=\"combined stocks\",\n",
    "#     stocks=stocks\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6icPey5v9hb"
   },
   "source": [
    "### Import Sample Data from the Files with the Generated Subset of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KRbsmepcv8ta"
   },
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file\n",
    "x_path = f'{x_in_path}{x_filename_out}'\n",
    "y_path = f'{y_in_path}{y_filename_out}'\n",
    "# Import data\n",
    "sp500_df = pd.read_csv(x_path)\n",
    "y = pd.read_csv(y_path)\n",
    "# Adjust labels\n",
    "y['target'] = y['ret_fwd_84']\n",
    "# Create additional time features\n",
    "sp500_df = create_time_feature(sp500_df)\n",
    "# Combine features and target\n",
    "sp500_df = pd.concat([sp500_df.iloc[:, 1:], y['target']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2NQB_arlnQjr"
   },
   "outputs": [],
   "source": [
    "# sp500_df = sp500_df[sp500_df['ticker'] == 'ADBE']\n",
    "# y = y[y['ticker'] == 'ADBE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ed5zN-sAISYF"
   },
   "outputs": [],
   "source": [
    "# sp500_df = sp500_df.iloc[:1000, -100:]\n",
    "# y = y.iloc[:1000, -100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "yY-miM1o6_Xp",
    "outputId": "64ec5e46-5ce0-4a99-f455-a12a8f438491"
   },
   "outputs": [],
   "source": [
    "display(y.head())\n",
    "print(f\"Dataset Shape: {np.shape(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "7wZ5t-JS1CL_",
    "outputId": "2092ee4e-2331-4150-fe9f-f177aa6450f9"
   },
   "outputs": [],
   "source": [
    "display(sp500_df.head())\n",
    "print(f\"Dataset Shape: {np.shape(sp500_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4Ue9n8mjlkD"
   },
   "source": [
    "### Initialize Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A2IixH9AjlkD",
    "outputId": "b8f4aef5-bf5a-4e0b-8a76-d8cf3f6cf54a"
   },
   "outputs": [],
   "source": [
    "# Possible train validation splits\n",
    "train_test_list = [tune_cv_split(\n",
    "    sp500_df.iloc[-np.shape(sp500_df)[0]:,:],\n",
    "    val_test_prop_constraint = 0.2, # Size of validation set relative to the train set\n",
    "    num_split_constraint = 5 # Number of splits\n",
    ")[-1]]\n",
    "\n",
    "keep_data_index = train_test_list[0][0]*train_test_list[0][2] + 2*train_test_list[0][1]\n",
    "print(f\"\\nUsing Split: {train_test_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nb6IrxLDelkn"
   },
   "outputs": [],
   "source": [
    "r1 = run(\n",
    "    cross_validation_type= \"moving window\", # or \"expanding window\"\n",
    "    save_output_file = True, # Whether to save test outputs\n",
    "    raw_df = sp500_df.iloc[-keep_data_index:, :].reset_index(drop=True), # Discard extra data instances from the beginning of the time series rather than the end\n",
    "    y = y.iloc[-keep_data_index:, :].reset_index(drop=True), # Discard extra data instances from the beginning of the time series rather than the end\n",
    "    train_test_list = train_test_list, # A list of possible list of train and validation size, and number of splits\n",
    "    methods = [\"xgboost\", \"permutation\", \"shap\", \"lasso\", \"cart\"], # Available methods: [\"xgboost\", \"cae\", \"permutation\", \"shap\", \"boruta\", \"sage\", \"lasso\", \"cart\", \"svm\", \"rf\", \"stg\", \"dynamic\"]\n",
    "    rebalance_type = [\"None\"], # [\"borderlinesmote\", \"smoten\", \"random_over_sampler\", \"smote\", \"None\"]\n",
    "    label_cols = [], # Columns to label encode\n",
    "    do_not_encode_cols = [\"dayofmonth\", \"dayofweek\", \"quarter\", \"month\", \"year\", \"dayofyear\", \"weekofyear\"], # These fields are not transformed\n",
    "    seed = 42,\n",
    "    target_colname = \"target\", # The name of the field that holds the true values\n",
    "    dataset_name = \"sp500\",\n",
    "    pred_type = \"regression\",\n",
    "    append_to_full_df = False,\n",
    "    n_features = 50,  # The number of top features to filter for\n",
    "    feature_direction = \"top\", # Feature order based on their scores in descending order\n",
    "    train_outputs_file_name = None,\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"),\n",
    "    scaler_filename = \"./feature_selection_timeseries/data/processed/scaler_saved.save\",\n",
    "    encoder_filename = \"./feature_selection_timeseries/data/processed/encoder_saved.save\",\n",
    "    label_encoder_filename = \"./feature_selection_timeseries/data/processed/lalbel_encoder_saved.save\",\n",
    "    test_output_file_name = f\"./feature_selection_timeseries/data/experiment/Consolidated_Stocks_FS_timeseries_sp500_outputs_test_results_\",\n",
    "    test_pred_file_name = f\"./feature_selection_timeseries/data/experiment/Consolidated_Stocks_FS_timeseries_sp500_outputs_test_preds_\",\n",
    "    print_outputs_train = False,\n",
    "    print_outputs_test = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVoJjXSLIl14"
   },
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLtN1BT4XFfM"
   },
   "outputs": [],
   "source": [
    "r1.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTwhrCJvjlkE"
   },
   "source": [
    "#### Test on holdout test data and generate testing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrBAbbgvsXHQ"
   },
   "outputs": [],
   "source": [
    "r1.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ky_env_sep28",
   "language": "python",
   "name": "ky_env_sep28"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
